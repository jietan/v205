---
title: 'Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language
  Models'
section: Poster
openreview: lV-rNbXVSaO
abstract: " We study open-world 3D scene understanding, a family of tasks that require
  agents to reason about their 3D environment with an open-set vocabulary and out-of-domain
  visual inputs â€“ a critical skill for robots to operate in the unstructured 3D world.
  Towards this end, we propose Semantic Abstraction (SemAbs), a framework that equips
  2D Vision-Language Models (VLMs) with new 3D spatial capabilities, while maintaining
  their zero-shot robustness. We achieve this abstraction using relevancy maps extracted
  from CLIP and learn 3D spatial and geometric reasoning skills on top of those abstractions
  in a semantic-agnostic manner. We demonstrate the usefulness of SemAbs on two open-world
  3D scene understanding tasks: 1) completing partially observed objects and 2) localizing
  hidden objects from language descriptions. Experiments show that SemAbs can generalize
  to novel vocabulary, materials/lighting, classes, and domains (i.e., real-world
  scans) from training on limited 3D synthetic data. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ha23a
month: 0
tex_title: 'Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language
  Models'
firstpage: 643
lastpage: 653
page: 643-653
order: 643
cycles: false
bibtex_author: Ha, Huy and Song, Shuran
author:
- given: Huy
  family: Ha
- given: Shuran
  family: Song
date: 2023-03-06
address:
container-title: Proceedings of The 6th Conference on Robot Learning
volume: '205'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 3
  - 6
pdf: https://proceedings.mlr.press/v205/ha23a/ha23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v205/ha23a/ha23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
