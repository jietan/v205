---
title: Learning Interpretable BEV Based VIO without Deep Neural Networks
section: Poster
openreview: 00OqOl4txhe
abstract: 'Monocular visual-inertial odometry (VIO) is a critical problem in robotics
  and autonomous driving. Traditional methods solve this problem based on filtering
  or optimization. While being fully interpretable, they rely on manual interference
  and empirical parameter tuning. On the other hand, learning-based approaches allow
  for end-to-end training but require a large number of training data to learn millions
  of parameters. However, the non-interpretable and heavy models hinder the generalization
  ability. In this paper, we propose a fully differentiable, and interpretable, bird-eye-view
  (BEV) based VIO model for robots with local planar motion that can be trained without
  deep neural networks. Specifically, we first adopt Unscented Kalman Filter as a
  differentiable layer to predict the pitch and roll, where the covariance matrices
  of noise are learned to filter out the noise of the IMU raw data.  Second, the refined
  pitch and roll are adopted to retrieve a gravity-aligned BEV image of each frame
  using differentiable camera projection. Finally, a differentiable pose estimator
  is utilized to estimate the remaining 3 DoF poses between the BEV frames: leading
  to a 5 DoF pose estimation. Our method allows for learning the covariance matrices
  end-to-end supervised by the pose estimation loss, demonstrating superior performance
  to empirical baselines. Experimental results on synthetic and real-world datasets
  demonstrate that our simple approach is competitive with state-of-the-art methods
  and generalizes well on unseen scenes.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23c
month: 0
tex_title: Learning Interpretable BEV Based VIO without Deep Neural Networks
firstpage: 1289
lastpage: 1298
page: 1289-1298
order: 1289
cycles: false
bibtex_author: Chen, Zexi and Du, Haozhe and XU, Xuecheng and Xiong, Rong and Liao,
  Yiyi and Wang, Yue
author:
- given: Zexi
  family: Chen
- given: Haozhe
  family: Du
- given: Xuecheng
  family: XU
- given: Rong
  family: Xiong
- given: Yiyi
  family: Liao
- given: Yue
  family: Wang
date: 2023-03-06
address:
container-title: Proceedings of The 6th Conference on Robot Learning
volume: '205'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 3
  - 6
pdf: https://proceedings.mlr.press/v205/chen23c/chen23c.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v205/chen23c/chen23c-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
