---
title: Deep Black-Box Reinforcement Learning with Movement Primitives
section: Poster
openreview: gJhuiYQ6VGJ
abstract: Episode-based reinforcement learning (ERL) algorithms treat reinforcement
  learning (RL) as a black-box optimization problem where we learn to select a parameter
  vector of a controller, often represented as a movement primitive, for a given task
  descriptor called a context. ERL offers several distinct benefits in comparison
  to step-based RL. It generates smooth control trajectories, can handle non-Markovian
  reward definitions, and the resulting exploration in parameter space is well suited
  for solving sparse reward settings. Yet, the high dimensionality of the movement
  primitive parameters has so far hampered the effective use of deep RL methods. In
  this paper, we present a new algorithm for deep ERL. It is based on differentiable
  trust region layers, a successful on-policy deep RL algorithm. These layers allow
  us to specify trust regions for the policy update that are solved exactly for each
  state using convex optimization, which enables policies learning with the high precision
  required for the ERL. We compare our ERL algorithm to state-of-the-art step-based
  algorithms in many complex simulated robotic control tasks. In doing so, we investigate
  different reward formulations - dense, sparse, and non-Markovian. While step-based
  algorithms perform well only on dense rewards, ERL performs favorably on sparse
  and non-Markovian rewards. Moreover, our results show that the sparse and the non-Markovian
  rewards are also often better suited to define the desired behavior, allowing us
  to obtain considerably higher quality policies compared to step-based RL.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: otto23a
month: 0
tex_title: Deep Black-Box Reinforcement Learning with Movement Primitives
firstpage: 1244
lastpage: 1265
page: 1244-1265
order: 1244
cycles: false
bibtex_author: Otto, Fabian and Celik, Onur and Zhou, Hongyi and Ziesche, Hanna and
  Ngo, Vien Anh and Neumann, Gerhard
author:
- given: Fabian
  family: Otto
- given: Onur
  family: Celik
- given: Hongyi
  family: Zhou
- given: Hanna
  family: Ziesche
- given: Vien Anh
  family: Ngo
- given: Gerhard
  family: Neumann
date: 2023-03-06
address:
container-title: Proceedings of The 6th Conference on Robot Learning
volume: '205'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 3
  - 6
pdf: https://proceedings.mlr.press/v205/otto23a/otto23a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v205/otto23a/otto23a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
