---
title: 'RoboTube: Learning Household Manipulation from Human Videos with Simulated
  Twin Environments'
section: Oral
openreview: VD0nXUG5Qk
abstract: 'We aim to build a useful, reproducible, democratized benchmark for learning
  household robotic manipulation from human videos. To realize this goal, a diverse,
  high-quality human video dataset curated specifically for robots is desired. To
  evaluate the learning progress, a simulated twin environment that resembles the
  appearance and the dynamics of the physical world would help roboticists and AI
  researchers validate their algorithms convincingly and efficiently before testing
  on a real robot. Hence, we present RoboTube, a human video dataset, and its digital
  twins for learning various robotic manipulation tasks. RoboTube video dataset contains
  5,000 video demonstrations recorded with multi-view RGB-D cameras of human-performing
  everyday household tasks including manipulation of rigid objects, articulated objects,
  deformable objects, and bimanual manipulation. RT-sim, as the simulated twin environments,
  consists of 3D scanned, photo-realistic objects, minimizing the visual domain gap
  between the physical world and the simulated environment. After extensively benchmarking
  existing methods in the field of robot learning from videos, the empirical results
  suggest that knowledge and models learned from the RoboTube video dataset can be
  deployed, benchmarked, and reproduced in RT-sim and be transferred to a real robot.
  We hope RoboTube can lower the barrier to robotics research for beginners while
  facilitating reproducible research in the community. More experiments and videos
  can be found in the supplementary materials and on the website: https://sites.google.com/view/robotube'
video: https://sites.google.com/view/robotube
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xiong23a
month: 0
tex_title: 'RoboTube: Learning Household Manipulation from Human Videos with Simulated
  Twin Environments'
firstpage: 1
lastpage: 10
page: 1-10
order: 1
cycles: false
bibtex_author: Xiong, Haoyu and Fu, Haoyuan and Zhang, Jieyi and Bao, Chen and Zhang,
  Qiang and Huang, Yongxi and Xu, Wenqiang and Garg, Animesh and Lu, Cewu
author:
- given: Haoyu
  family: Xiong
- given: Haoyuan
  family: Fu
- given: Jieyi
  family: Zhang
- given: Chen
  family: Bao
- given: Qiang
  family: Zhang
- given: Yongxi
  family: Huang
- given: Wenqiang
  family: Xu
- given: Animesh
  family: Garg
- given: Cewu
  family: Lu
date: 2023-03-06
address:
container-title: Proceedings of The 6th Conference on Robot Learning
volume: '205'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 3
  - 6
pdf: https://proceedings.mlr.press/v205/xiong23a/xiong23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
