---
title: Generative Category-Level Shape and Pose Estimation with Semantic Primitives
section: Poster
openreview: N78I92JIqOJ
abstract: Empowering autonomous agents with 3D understanding for daily objects is
  a grand challenge in robotics applications. When exploring in an unknown environment,
  existing methods for object pose estimation are still not satisfactory due to the
  diversity of object shapes. In this paper, we propose a novel framework for category-level
  object shape and pose estimation from a single RGB-D image. To handle the intra-category
  variation, we adopt a semantic primitive representation that encodes diverse shapes
  into a unified latent space, which is the key to establish reliable correspondences
  between observed point clouds and estimated shapes. Then, by using a SIM(3)-invariant
  shape descriptor, we gracefully decouple the shape and pose of an object, thus supporting
  latent shape optimization of target objects in arbitrary poses. Extensive experiments
  show that the proposed method achieves SOTA pose estimation performance and better
  generalization in the real-world dataset. Code and video are available at https://zju3dv.github.io/gCasp.
software: https://zju3dv.github.io/gCasp
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23d
month: 0
tex_title: Generative Category-Level Shape and Pose Estimation with Semantic Primitives
firstpage: 1390
lastpage: 1400
page: 1390-1400
order: 1390
cycles: false
bibtex_author: Li, Guanglin and Li, Yifeng and Ye, Zhichao and Zhang, Qihang and Kong,
  Tao and Cui, Zhaopeng and Zhang, Guofeng
author:
- given: Guanglin
  family: Li
- given: Yifeng
  family: Li
- given: Zhichao
  family: Ye
- given: Qihang
  family: Zhang
- given: Tao
  family: Kong
- given: Zhaopeng
  family: Cui
- given: Guofeng
  family: Zhang
date: 2023-03-06
address:
container-title: Proceedings of The 6th Conference on Robot Learning
volume: '205'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 3
  - 6
pdf: https://proceedings.mlr.press/v205/li23d/li23d.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v205/li23d/li23d-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
